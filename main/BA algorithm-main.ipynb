{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc5a36bf",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_train_test(data,test_ratio):\n",
    "    np.random.seed(42)\n",
    "\tshuffled = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled[:test_set_size]\n",
    "    train_indices = shuffled[test_set_size:]\n",
    "    return data.iloc[train_indiced, data.iloc[test_indices]]\n",
    "    \n",
    "train_set, test_set = split_train_test(data,0.2)\n",
    "print(f\"Rows in train set: {len(train_set)}\\n ROws in test set: {len(train_set)}\\n\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size = 0.2, random_state =42)\n",
    "print(f\"Rows in train set: {len(train_set)}\\n ROws in test set: {len(train_set)}\\n\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size  = 0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cd06f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d39ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2870df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.read_csv(\"data_process_v2.csv\", engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e48eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boruta in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boruta) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boruta) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from boruta) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->boruta) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn>=0.17.1->boruta) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install boruta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53381e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical_cols = df_ba.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Print the categorical columns\n",
    "#print(\"Categorical features:\", categorical_cols)\n",
    "#df_ba['local_authority_(highway)']\n",
    "# Convert categorical features to numeric values using label encoding\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#categorical_cols = df_ba.select_dtypes(include=['object']).columns.tolist()\n",
    "#le = LabelEncoder()\n",
    "#df_ba.isna().sum()[categorical_cols] = df_ba[categorical_cols].apply(lambda col: le.fit_transform(col))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586252c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t24\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t1\n",
      "Rejected: \t20\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t0\n",
      "Rejected: \t21\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t3\n",
      "Tentative: \t0\n",
      "Rejected: \t21\n",
      "Selected Features:  [False False False  True False False False False False False False False\n",
      "  True False False False False False False False False False False  True]\n",
      "Ranking of Features:  [ 4 21 18  1  7  2 19  3 11  5  8 15  1  6  9 12 14 22 13 10 16 17 20  1]\n"
     ]
    }
   ],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_ba = pd.read_csv(\"data_process_v2.csv\", engine = \"python\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = df_ba.select_dtypes(include=['object']).columns.tolist()\n",
    "le = LabelEncoder()\n",
    "df_encoded = df_ba.copy()\n",
    "df_encoded[categorical_cols] = df_ba[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "# Separate the target variable from the predictor variables\n",
    "X = df_encoded.drop('accident_severity', axis=1).values\n",
    "y = df_encoded['accident_severity'].values\n",
    "# Train a Random Forest model on the dataset\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X, y)\n",
    "# Create a BorutaPy object and fit it to the dataset\n",
    "boruta_selector = BorutaPy(rf, n_estimators='auto', verbose=2)\n",
    "boruta_selector.fit(X, y)\n",
    "# Print the results\n",
    "print(\"Selected Features: \", boruta_selector.support_)\n",
    "print(\"Ranking of Features: \", boruta_selector.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a83826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age_of_driver', 'speed_limit', 'urban_or_rural_area'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#This error occurs because the boolean mask generated by boruta_selector.support_ is of length 60, while the original dataset df_ba has 61 columns (after dropping the time column).\n",
    "\n",
    "len(df_encoded.columns)\n",
    "df_encoded.drop(['accident_severity'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selected_features = df_encoded.columns[boruta_selector.support_]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2849e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    feature  rank\n",
      "23                      urban_or_rural_area     1\n",
      "12                              speed_limit     1\n",
      "3                             age_of_driver     1\n",
      "5                      engine_capacity_(cc)     2\n",
      "7                            age_of_vehicle     3\n",
      "0                              vehicle_type     4\n",
      "9                               day_of_week     5\n",
      "13                          junction_detail     6\n",
      "4                        age_band_of_driver     7\n",
      "10                           1st_road_class     8\n",
      "14                         junction_control     9\n",
      "19                         light_conditions    10\n",
      "8                        number_of_vehicles    11\n",
      "15                           2nd_road_class    12\n",
      "18  pedestrian_crossing-physical_facilities    13\n",
      "16                          2nd_road_number    14\n",
      "11                                road_type    15\n",
      "20                       weather_conditions    16\n",
      "21                  road_surface_conditions    17\n",
      "2                             sex_of_driver    18\n",
      "6                           propulsion_code    19\n",
      "22               special_conditions_at_site    20\n",
      "1                   towing_and_articulation    21\n",
      "17        pedestrian_crossing-human_control    22\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = None\n",
    "ranking = pd.DataFrame({'feature': df_encoded.columns, 'rank': boruta_selector.ranking_})\n",
    "ranking = ranking.sort_values('rank')\n",
    "print(ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77946e02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
